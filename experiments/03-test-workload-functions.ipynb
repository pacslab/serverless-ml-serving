{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04f7b070ef049bbd8502237a868479304b4da16a010bb509c19371ab8ff01cc23",
   "display_name": "Python 3.8.5 64-bit ('miniconda': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Prepare Workloads\n",
    "\n",
    "In this notebook, we will try to prepare the workloads that we will be applying\n",
    "to the deployments. Potentially, this leads to functions that will be called\n",
    "when we want to send traffic to the deployment and we want to measure the system's\n",
    "performance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fetching imagenet v2\nresizing images\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9417ac3f877487792cc5fa8afd7cfcb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converting to bentoml files\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2423f178d0a04a41a99b64976fa519c9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "extracting base64 files\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff7605fe9dfd42aba53a52fd4f359074"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "preprocessing for mobilenet\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e014cc74de804ccba2affaf095e71cac"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# my imports\n",
    "from helpers import kube\n",
    "from helpers import workload\n",
    "from helpers import util\n",
    "from helpers import request_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "configurables: ['batch_size']\n",
      "{'batch_size': 1}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d348475339934c928b1efbbb80b3f360"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 5}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 5\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4af9ebd8aca3470aad975fc255566e79"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 10}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 10\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdf174a50a6a474e987afcc609b69714"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 20}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 20\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e9fd74e8f2142e6911e0f7013deecb1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 50}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 50\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d559ac9f9ba4a1f9b6d9f19554d2162"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 100}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 100\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91d5fd214e5049fba4faf5b6cf455993"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "def experiment_batch(warmup_req_count, total_req_count, batch_size, service_name, ):\n",
    "    # an array as the same length as \n",
    "    batch_results = {\n",
    "        'response_times_ms': [],\n",
    "    }\n",
    "    reqs_failed = 0\n",
    "    reqs_succeeded = 0\n",
    "\n",
    "    print('warming up...')\n",
    "    for _ in range(warmup_req_count):\n",
    "        try:\n",
    "            # discard the results\n",
    "            request_funcs.workload_funcs[service_name](batch_size=batch_size)\n",
    "        except Exception:\n",
    "            print('exception occured:')\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # running the main workload\n",
    "    print(f'running {service_name} workload function, batch_size: {batch_size}')\n",
    "    for _ in tqdm(range(total_req_count)):\n",
    "        try:\n",
    "            result = request_funcs.workload_funcs[service_name](batch_size=batch_size)\n",
    "            batch_results['response_times_ms'].append(result['response_time_ms'])\n",
    "            reqs_succeeded += 1\n",
    "        except Exception:\n",
    "            print('exception occured:')\n",
    "            traceback.print_exc()\n",
    "            reqs_failed += 1\n",
    "\n",
    "    batch_results.update({\n",
    "        'reqs_failed': reqs_failed,\n",
    "        'reqs_succeeded': reqs_succeeded,\n",
    "    })\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "def perform_experiment_batch(config):\n",
    "    # configurables = ['batch_size']\n",
    "    configurables = [k for k in config if isinstance(config[k], list)]\n",
    "    print(f'configurables: {configurables}')\n",
    "\n",
    "    # make a copy of config\n",
    "    config_base = {k:config[k] for k in config if k not in configurables}\n",
    "    configurable_base = {k:config[k] for k in config if k in configurables}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    config_combinations_keys = list(configurable_base.keys())\n",
    "    for config_combination in itertools.product(*configurable_base.values()):\n",
    "        configurable = {config_combinations_keys[i]: config_combination[i]  for i in range(len(config_combinations_keys))}\n",
    "        \n",
    "        print(configurable)\n",
    "        new_config = {**config_base}\n",
    "        new_config.update(configurable)\n",
    "\n",
    "        result = experiment_batch(**new_config)\n",
    "        new_config.update(result)\n",
    "        results.append(new_config)\n",
    "        \n",
    "    return results\n",
    "\n",
    "config = {\n",
    "    'warmup_req_count': 20,\n",
    "    'total_req_count': 100,\n",
    "    'service_name': 'bentoml-iris',\n",
    "    'batch_size': [1,5,10,20,50,100],\n",
    "}\n",
    "results = perform_experiment_batch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   warmup_req_count  total_req_count  service_name  batch_size  \\\n",
       "0                20              100  bentoml-iris           1   \n",
       "1                20              100  bentoml-iris           5   \n",
       "2                20              100  bentoml-iris          10   \n",
       "3                20              100  bentoml-iris          20   \n",
       "4                20              100  bentoml-iris          50   \n",
       "5                20              100  bentoml-iris         100   \n",
       "\n",
       "                                   response_times_ms  reqs_failed  \\\n",
       "0  [26.89, 18.044, 20.230999999999998, 17.253, 18...            0   \n",
       "1  [20.544, 20.009, 21.628999999999998, 17.489, 1...            0   \n",
       "2  [24.203, 23.233, 19.293000000000003, 20.333000...            0   \n",
       "3  [24.035, 20.756, 18.629, 18.707, 22.9290000000...            0   \n",
       "4  [35.085, 59.354, 35.26, 246.504, 251.726999999...            0   \n",
       "5  [43.67, 37.456, 45.902, 39.786, 249.002, 23.23...            0   \n",
       "\n",
       "   reqs_succeeded  resp_time_avg  resp_time_p50  resp_time_p90  resp_time_p95  \\\n",
       "0             100       19.96643        19.4410        23.3454       24.41720   \n",
       "1             100       20.88932        19.7870        23.8896       27.23205   \n",
       "2             100       20.74498        20.1935        23.8052       25.93745   \n",
       "3             100       24.47792        20.4695        24.9953       35.47165   \n",
       "4             100       51.07665        35.8220        55.6829      244.94505   \n",
       "5             100       75.57895        39.9425       246.3886      249.97240   \n",
       "\n",
       "   resp_time_p99  \n",
       "0       28.08538  \n",
       "1       34.07918  \n",
       "2       30.95694  \n",
       "3       88.38873  \n",
       "4      248.95401  \n",
       "5      272.32491  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>warmup_req_count</th>\n      <th>total_req_count</th>\n      <th>service_name</th>\n      <th>batch_size</th>\n      <th>response_times_ms</th>\n      <th>reqs_failed</th>\n      <th>reqs_succeeded</th>\n      <th>resp_time_avg</th>\n      <th>resp_time_p50</th>\n      <th>resp_time_p90</th>\n      <th>resp_time_p95</th>\n      <th>resp_time_p99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>100</td>\n      <td>bentoml-iris</td>\n      <td>1</td>\n      <td>[26.89, 18.044, 20.230999999999998, 17.253, 18...</td>\n      <td>0</td>\n      <td>100</td>\n      <td>19.96643</td>\n      <td>19.4410</td>\n      <td>23.3454</td>\n      <td>24.41720</td>\n      <td>28.08538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>100</td>\n      <td>bentoml-iris</td>\n      <td>5</td>\n      <td>[20.544, 20.009, 21.628999999999998, 17.489, 1...</td>\n      <td>0</td>\n      <td>100</td>\n      <td>20.88932</td>\n      <td>19.7870</td>\n      <td>23.8896</td>\n      <td>27.23205</td>\n      <td>34.07918</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>100</td>\n      <td>bentoml-iris</td>\n      <td>10</td>\n      <td>[24.203, 23.233, 19.293000000000003, 20.333000...</td>\n      <td>0</td>\n      <td>100</td>\n      <td>20.74498</td>\n      <td>20.1935</td>\n      <td>23.8052</td>\n      <td>25.93745</td>\n      <td>30.95694</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20</td>\n      <td>100</td>\n      <td>bentoml-iris</td>\n      <td>20</td>\n      <td>[24.035, 20.756, 18.629, 18.707, 22.9290000000...</td>\n      <td>0</td>\n      <td>100</td>\n      <td>24.47792</td>\n      <td>20.4695</td>\n      <td>24.9953</td>\n      <td>35.47165</td>\n      <td>88.38873</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20</td>\n      <td>100</td>\n      <td>bentoml-iris</td>\n      <td>50</td>\n      <td>[35.085, 59.354, 35.26, 246.504, 251.726999999...</td>\n      <td>0</td>\n      <td>100</td>\n      <td>51.07665</td>\n      <td>35.8220</td>\n      <td>55.6829</td>\n      <td>244.94505</td>\n      <td>248.95401</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20</td>\n      <td>100</td>\n      <td>bentoml-iris</td>\n      <td>100</td>\n      <td>[43.67, 37.456, 45.902, 39.786, 249.002, 23.23...</td>\n      <td>0</td>\n      <td>100</td>\n      <td>75.57895</td>\n      <td>39.9425</td>\n      <td>246.3886</td>\n      <td>249.97240</td>\n      <td>272.32491</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def post_process(df):\n",
    "    df['resp_time_avg'] = df.apply(lambda x: np.mean(x['response_times_ms']), axis=1)\n",
    "    for percentile in [50,90,95,99]:\n",
    "        df[f'resp_time_p{percentile}'] = df.apply(lambda x: np.percentile(x['response_times_ms'], percentile), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=results)\n",
    "df = post_process(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "configurables: ['batch_size']\n",
      "{'batch_size': 1}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "350a0e211725472384c058f84ff523d6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 5}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 5\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afecbddb16ff461294971c6296cfa77f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 10}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 10\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e363aecd0baa41c18940db42dfd12177"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 20}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 20\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fabe12e508004292881a8b81aff8b86e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 50}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 50\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00a86a316fab4791a44bd57022293ae3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 100}\n",
      "warming up...\n",
      "running bentoml-iris workload function, batch_size: 100\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a08090d94ae4df6853e3d2309bac3a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "res_name: bentoml-iris_2021-05-04_23-13-34\n"
     ]
    }
   ],
   "source": [
    "all_configs = [\n",
    "    {\n",
    "        'warmup_req_count': 200,\n",
    "        'total_req_count': 1000,\n",
    "        'service_name': 'bentoml-iris',\n",
    "        'batch_size': [1,5,10,20,50,100],\n",
    "    },\n",
    "    {\n",
    "        'warmup_req_count': 20,\n",
    "        'total_req_count': 1000,\n",
    "        'service_name': 'tfserving-resnetv2',\n",
    "        'batch_size': [1,2,3,5,10],\n",
    "    },\n",
    "    {\n",
    "        'warmup_req_count': 20,\n",
    "        'total_req_count': 1000,\n",
    "        'service_name': 'tfserving-mobilenetv1',\n",
    "        'batch_size': [1,2,3,5,10],\n",
    "    },\n",
    "]\n",
    "\n",
    "results_folder = './results/batch_experiments_defult'\n",
    "!mkdir -p {results_folder}\n",
    "for config in all_configs:\n",
    "    service_name = config['service_name']\n",
    "\n",
    "    results = perform_experiment_batch(config)\n",
    "    df = pd.DataFrame(data=results)\n",
    "\n",
    "    now = util.get_time_with_tz()\n",
    "    res_name = now.strftime(f'{service_name}_%Y-%m-%d_%H-%M-%S')\n",
    "    print('res_name:', res_name)\n",
    "    df.to_csv(f'{results_folder}/{res_name}.csv')"
   ]
  }
 ]
}