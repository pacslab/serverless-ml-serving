{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4f7b070ef049bbd8502237a868479304b4da16a010bb509c19371ab8ff01cc23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preparing Experiments\n",
    "\n",
    "In this notebook, we will prepare several parts of our experiments including\n",
    "deploying and configuring our workload, loading traces, and creating functions\n",
    "to be called to generate the workloads."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# my imports\n",
    "from helpers import kube\n",
    "from helpers import workload\n",
    "from helpers import util\n",
    "# from helpers import request_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NAME                    URL                                                          LATEST                        AGE   CONDITIONS   READY   REASON\nbentoml-iris            http://bentoml-iris.default.192-168-23-125.nip.io            bentoml-iris-00009            37d   3 OK / 3     True    \nbentoml-onnx-resnet50   http://bentoml-onnx-resnet50.default.192-168-23-125.nip.io   bentoml-onnx-resnet50-00005   36d   3 OK / 3     True    \nhelloworld-go           http://helloworld-go.default.192-168-23-125.nip.io           helloworld-go-00001           37d   3 OK / 3     True    \ntfserving-mobilenetv1   http://tfserving-mobilenetv1.default.192-168-23-125.nip.io   tfserving-mobilenetv1-00005   36d   3 OK / 3     True    \ntfserving-resnetv2      http://tfserving-resnetv2.default.192-168-23-125.nip.io      tfserving-resnetv2-00004      37d   3 OK / 3     True    \n"
     ]
    }
   ],
   "source": [
    "# making sure kn is set up correctly\n",
    "!kn service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====================\n",
      "kn service apply bentoml-iris --image ghcr.io/nimamahmoudi/bentoml-iris-classifier:20210429201447 \\\n",
      "  --limit 'cpu=1000m,memory=1000Mi' \\\n",
      "  --request 'cpu=1000m,memory=1000Mi' \\\n",
      "  --port 5000 \\\n",
      "  -a autoscaling.knative.dev/target=1 \\\n",
      "  -a autoscaling.knative.dev/metric=concurrency\n",
      "--------------------\n",
      "Applying service 'bentoml-iris' in namespace 'default':\n",
      "\n",
      "  0.018s The Configuration is still working to reflect the latest desired specification.\n",
      "  9.392s Traffic is not yet migrated to the latest revision.\n",
      "  9.415s Ingress has not yet been reconciled.\n",
      "  9.450s Waiting for load balancer to be ready\n",
      "  9.626s Ready to serve.\n",
      "\n",
      "Service 'bentoml-iris' applied to latest revision 'bentoml-iris-00010' is available at URL:\n",
      "http://bentoml-iris.default.192-168-23-125.nip.io\n",
      "====================\n",
      "kn service apply bentoml-onnx-resnet50 --image ghcr.io/nimamahmoudi/bentoml-onnx-resnet50-b64:20210505124300 \\\n",
      "  --limit 'cpu=1000m,memory=1000Mi' \\\n",
      "  --request 'cpu=1000m,memory=1000Mi' \\\n",
      "  --port 5000 \\\n",
      "  -a autoscaling.knative.dev/target=1 \\\n",
      "  -a autoscaling.knative.dev/metric=concurrency\n",
      "--------------------\n",
      "Applying service 'bentoml-onnx-resnet50' in namespace 'default':\n",
      "\n",
      "  0.021s The Configuration is still working to reflect the latest desired specification.\n",
      "  8.581s Traffic is not yet migrated to the latest revision.\n",
      "  8.606s Ingress has not yet been reconciled.\n",
      "  8.643s Waiting for load balancer to be ready\n",
      "  9.171s Ready to serve.\n",
      "\n",
      "Service 'bentoml-onnx-resnet50' applied to latest revision 'bentoml-onnx-resnet50-00006' is available at URL:\n",
      "http://bentoml-onnx-resnet50.default.192-168-23-125.nip.io\n",
      "====================\n",
      "kn service apply tfserving-resnetv2 --image ghcr.io/nimamahmoudi/tfserving-resnet:20210429213000 \\\n",
      "  --limit 'cpu=1000m,memory=1000Mi' \\\n",
      "  --request 'cpu=1000m,memory=1000Mi' \\\n",
      "  --port 5000 \\\n",
      "  -a autoscaling.knative.dev/target=1 \\\n",
      "  -a autoscaling.knative.dev/metric=concurrency\n",
      "--------------------\n",
      "Applying service 'tfserving-resnetv2' in namespace 'default':\n",
      "\n",
      "  0.018s The Configuration is still working to reflect the latest desired specification.\n",
      "  3.339s Traffic is not yet migrated to the latest revision.\n",
      "  3.363s Ingress has not yet been reconciled.\n",
      "  3.427s Waiting for load balancer to be ready\n",
      "  3.575s Ready to serve.\n",
      "\n",
      "Service 'tfserving-resnetv2' applied to latest revision 'tfserving-resnetv2-00005' is available at URL:\n",
      "http://tfserving-resnetv2.default.192-168-23-125.nip.io\n",
      "====================\n",
      "kn service apply tfserving-mobilenetv1 --image ghcr.io/nimamahmoudi/tfserving-mobilenet:20210430005829 \\\n",
      "  --limit 'cpu=1000m,memory=1000Mi' \\\n",
      "  --request 'cpu=1000m,memory=1000Mi' \\\n",
      "  --port 5000 \\\n",
      "  -a autoscaling.knative.dev/target=1 \\\n",
      "  -a autoscaling.knative.dev/metric=concurrency\n",
      "--------------------\n",
      "Applying service 'tfserving-mobilenetv1' in namespace 'default':\n",
      "\n",
      "  0.021s The Configuration is still working to reflect the latest desired specification.\n",
      "  3.765s Traffic is not yet migrated to the latest revision.\n",
      "  3.789s Ingress has not yet been reconciled.\n",
      "  3.823s Waiting for load balancer to be ready\n",
      "  4.011s Ready to serve.\n",
      "\n",
      "Service 'tfserving-mobilenetv1' applied to latest revision 'tfserving-mobilenetv1-00006' is available at URL:\n",
      "http://tfserving-mobilenetv1.default.192-168-23-125.nip.io\n",
      "====================\n",
      "kn service apply bentoml-pytorch-fashion-mnist --image ghcr.io/nimamahmoudi/bentoml-pytorch-fashion-mnist:20210614122950 \\\n",
      "  --limit 'cpu=1000m,memory=1000Mi' \\\n",
      "  --request 'cpu=1000m,memory=1000Mi' \\\n",
      "  --port 5000 \\\n",
      "  -a autoscaling.knative.dev/target=1 \\\n",
      "  -a autoscaling.knative.dev/metric=concurrency\n",
      "--------------------\n",
      "Creating service 'bentoml-pytorch-fashion-mnist' in namespace 'default':\n",
      "\n",
      "  0.021s The Route is still working to reflect the latest desired specification.\n",
      "  0.054s Configuration \"bentoml-pytorch-fashion-mnist\" is waiting for a Revision to become ready.\n",
      " 77.801s ...\n",
      " 77.835s Ingress has not yet been reconciled.\n",
      " 77.874s Waiting for load balancer to be ready\n",
      " 78.425s Ready to serve.\n",
      "\n",
      "Service 'bentoml-pytorch-fashion-mnist' created to latest revision 'bentoml-pytorch-fashion-mnist-00001' is available at URL:\n",
      "http://bentoml-pytorch-fashion-mnist.default.192-168-23-125.nip.io\n",
      "====================\n",
      "kn service apply bentoml-keras-toxic-comments --image ghcr.io/nimamahmoudi/bentoml-keras-toxic-comment-classification:20210622155420 \\\n",
      "  --limit 'cpu=1000m,memory=1000Mi' \\\n",
      "  --request 'cpu=1000m,memory=1000Mi' \\\n",
      "  --port 5000 \\\n",
      "  -a autoscaling.knative.dev/target=1 \\\n",
      "  -a autoscaling.knative.dev/metric=concurrency\n",
      "--------------------\n",
      "Creating service 'bentoml-keras-toxic-comments' in namespace 'default':\n",
      "\n",
      "  0.016s The Route is still working to reflect the latest desired specification.\n",
      "  0.057s Configuration \"bentoml-keras-toxic-comments\" is waiting for a Revision to become ready.\n",
      "  0.094s ...\n",
      " 53.623s ...\n",
      " 53.646s Ingress has not yet been reconciled.\n",
      " 53.686s Waiting for load balancer to be ready\n",
      " 54.040s Ready to serve.\n",
      "\n",
      "Service 'bentoml-keras-toxic-comments' created to latest revision 'bentoml-keras-toxic-comments-00001' is available at URL:\n",
      "http://bentoml-keras-toxic-comments.default.192-168-23-125.nip.io\n"
     ]
    }
   ],
   "source": [
    "# EXP_CONFIG_NAME_DEFAULT = 'bentoml-iris-250m-512mb'\n",
    "# EXP_CONFIG_NAME_DEFAULT = 'bentoml-onnx-resnet50-250m-512mb'\n",
    "# EXP_CONFIG_NAME_DEFAULT = 'tfserving-resnetv2-250m-512mb'\n",
    "# EXP_CONFIG_NAME_DEFAULT = 'tfserving-mobilenetv1-250m-512mb'\n",
    "# exp_config_name = os.getenv(\"DEPLOYMENT_CONFIG_NAME\", EXP_CONFIG_NAME_DEFAULT)\n",
    "\n",
    "config_names = [\n",
    "    'bentoml-iris-250m-512mb',\n",
    "    'bentoml-onnx-resnet50-250m-512mb',\n",
    "    'tfserving-resnetv2-250m-512mb',\n",
    "    'tfserving-mobilenetv1-250m-512mb',\n",
    "    'bentoml-pytorch-fashionmnist-250m-512mb',\n",
    "    'bentoml-keras-toxic-comments-250m-512mb',\n",
    "]\n",
    "\n",
    "request_limit_override = \"'cpu=1000m,memory=1000Mi'\"\n",
    "\n",
    "for exp_config_name in config_names:\n",
    "    exp_file = f\"deployments/{exp_config_name}.json\"\n",
    "\n",
    "    workload_spec = util.load_json_file(exp_file)\n",
    "\n",
    "    # override request and limit values\n",
    "    workload_spec['opts']['--request'] = request_limit_override\n",
    "    workload_spec['opts']['--limit'] = request_limit_override\n",
    "\n",
    "    kn_command = kube.get_kn_command(**workload_spec)\n",
    "    print('='*20)\n",
    "    print(kn_command)\n",
    "    print('-'*20)\n",
    "    # to run the command, we can simply use:\n",
    "    !{kn_command}\n",
    "    # or from python:\n",
    "    # get_ipython().system('{kn_command}')\n",
    "\n",
    "# wait for changes to take effect\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing the workload functions\n",
    "# !python helpers/request_funcs.py"
   ]
  }
 ]
}