{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04f7b070ef049bbd8502237a868479304b4da16a010bb509c19371ab8ff01cc23",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preparing Experiments\n",
    "\n",
    "In this notebook, we will prepare several parts of our experiments including\n",
    "deploying and configuring our workload, loading traces, and creating functions\n",
    "to be called to generate the workloads."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fetching imagenet v2\nresizing images\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7064214ac4104d63ac737813472641ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converting to bentoml files\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f07a77d36c0942149e914a8f19849b53"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "extracting base64 files\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27b9d9072486413092f73a7575b14a42"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "preprocessing for mobilenet\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92990b04c01e4ec6b425e3bbaded1de0"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "\n",
    "# my imports\n",
    "from helpers import kube\n",
    "from helpers import workload\n",
    "from helpers import util\n",
    "from helpers import request_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NAME                    URL                                                    LATEST                        AGE     CONDITIONS   READY   REASON\nautoscale-go            http://autoscale-go.default.kn.nima-dev.com            autoscale-go-00035            91d     3 OK / 3     True    \nbench1                  http://bench1.default.kn.nima-dev.com                  bench1-00054                  100d    3 OK / 3     True    \nbentoml-iris            http://bentoml-iris.default.kn.nima-dev.com            bentoml-iris-00003            2d21h   3 OK / 3     True    \nbentoml-onnx-resnet50   http://bentoml-onnx-resnet50.default.kn.nima-dev.com   bentoml-onnx-resnet50-00002   2d21h   3 OK / 3     True    \nhelloworld-go           http://helloworld-go.default.kn.nima-dev.com           helloworld-go-00001           101d    3 OK / 3     True    \ntfserving-mobilenetv1   http://tfserving-mobilenetv1.default.kn.nima-dev.com   tfserving-mobilenetv1-00002   2d20h   3 OK / 3     True    \ntfserving-resnetv2      http://tfserving-resnetv2.default.kn.nima-dev.com      tfserving-resnetv2-00002      2d20h   3 OK / 3     True    \n"
     ]
    }
   ],
   "source": [
    "# making sure kn is set up correctly\n",
    "!kn service ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "kn service apply bentoml-iris --image ghcr.io/nimamahmoudi/bentoml-iris-classifier:20210429201447 \\\n  --limit 'cpu=250m,memory=512Mi' \\\n  --request 'cpu=250m,memory=512Mi' \\\n  --port 5000 \\\n  -a autoscaling.knative.dev/target=1 \\\n  -a autoscaling.knative.dev/metric=concurrency\n"
     ]
    }
   ],
   "source": [
    "EXP_CONFIG_NAME_DEFAULT = 'bentoml-iris-250m-512mb'\n",
    "# EXP_CONFIG_NAME_DEFAULT = 'bentoml-onnx-resnet50-250m-512mb'\n",
    "# EXP_CONFIG_NAME_DEFAULT = 'tfserving-resnetv2-250m-512mb'\n",
    "# EXP_CONFIG_NAME_DEFAULT = 'tfserving-mobilenetv1-250m-512mb'\n",
    "exp_config_name = os.getenv(\"DEPLOYMENT_CONFIG_NAME\", EXP_CONFIG_NAME_DEFAULT)\n",
    "exp_file = f\"deployments/{exp_config_name}.json\"\n",
    "\n",
    "workload_spec = util.load_json_file(exp_file)\n",
    "\n",
    "kn_command = kube.get_kn_command(**workload_spec)\n",
    "print(kn_command)\n",
    "# to run the command, we can simply use:\n",
    "# !{kn_command}\n",
    "# or from python:\n",
    "# get_ipython().system('{kn_command}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No changes to apply to service 'bentoml-iris'.\nService 'bentoml-iris' with latest revision 'bentoml-iris-00003' (unchanged) is available at URL:\nhttp://bentoml-iris.default.kn.nima-dev.com\n"
     ]
    }
   ],
   "source": [
    "# deploy the workload\n",
    "!{kn_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-03 15:05:30.551174: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-05-03 15:05:30.551216: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-05-03 15:05:33.793577: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-05-03 15:05:33.793851: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-05-03 15:05:33.793886: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-05-03 15:05:33.793924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nima): /proc/driver/nvidia/version does not exist\n",
      "2021-05-03 15:05:33.794298: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-03 15:05:33.794765: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-05-03 15:05:33.855759: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-05-03 15:05:33.856388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n",
      "fetching imagenet v2\n",
      "resizing images\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 147.95it/s]\n",
      "converting to bentoml files\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 348.87it/s]\n",
      "extracting base64 files\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 376.26it/s]\n",
      "preprocessing for mobilenet\n",
      "100%|█████████████████████████████████████████| 100/100 [00:05<00:00, 18.20it/s]\n",
      "Starting testing...\n",
      "running bentoml-iris workload function\n",
      "[1]: result: {'prediction': 2, 'response_time_ms': 361.781}\n",
      "[2]: result: {'prediction': 0, 'response_time_ms': 85.25399999999999}\n",
      "[3]: result: {'prediction': 2, 'response_time_ms': 20.559}\n",
      "[4]: result: {'prediction': 1, 'response_time_ms': 71.315}\n",
      "[5]: result: {'prediction': 2, 'response_time_ms': 19.624}\n",
      "[6]: result: {'prediction': 1, 'response_time_ms': 73.514}\n",
      "[7]: result: {'prediction': 2, 'response_time_ms': 17.781000000000002}\n",
      "[8]: result: {'prediction': 1, 'response_time_ms': 21.002}\n",
      "[9]: result: {'prediction': 2, 'response_time_ms': 62.499}\n",
      "[10]: result: {'prediction': 2, 'response_time_ms': 20.648}\n",
      "running bentoml-onnx-resnet50 workload function\n",
      "[1]: result: {'prediction': ['langur', 'patas monkey', 'gibbon', 'black-and-white colobus', 'guenon'], 'response_time_ms': 5727.344}\n",
      "[2]: result: {'prediction': ['solar thermal collector', 'tent', 'radio telescope', 'yawl', 'sundial'], 'response_time_ms': 999.695}\n",
      "[3]: result: {'prediction': ['bolete', 'earth star', 'agaric', 'mushroom', 'stinkhorn mushroom'], 'response_time_ms': 1093.563}\n",
      "[4]: result: {'prediction': ['dust jacket', 'prayer rug', 'packet', 'carton', 'envelope'], 'response_time_ms': 1207.811}\n",
      "[5]: result: {'prediction': ['photocopier', 'printer', 'desktop computer', 'typewriter keyboard', 'upright piano'], 'response_time_ms': 1295.625}\n",
      "[6]: result: {'prediction': ['baguette', 'crate', 'guillotine', 'sawmill', 'ear'], 'response_time_ms': 1488.161}\n",
      "[7]: result: {'prediction': ['German Shepherd Dog', 'Norwegian Elkhound', 'Alaskan Malamute', 'Australian Kelpie', 'husky'], 'response_time_ms': 1003.393}\n",
      "[8]: result: {'prediction': ['echidna', 'platypus', 'partridge', 'porcupine', 'ruffed grouse'], 'response_time_ms': 1003.514}\n",
      "[9]: result: {'prediction': ['sea anemone', 'sea slug', 'sea urchin', 'chiton', 'chambered nautilus'], 'response_time_ms': 1094.414}\n",
      "[10]: result: {'prediction': ['hand-held computer', 'suit', 'Windsor tie', 'notebook computer', 'academic gown'], 'response_time_ms': 1097.749}\n",
      "running tfserving-resnetv2 workload function\n",
      "[1]: result: {'prediction': ['eggnog', 'chocolate_sauce', 'cup', 'bakery', 'ice_cream'], 'response_time_ms': 6695.218}\n",
      "[2]: result: {'prediction': ['bubble', 'Petri_dish', 'pretzel', 'strawberry', 'spider_web'], 'response_time_ms': 5441.703}\n",
      "[3]: result: {'prediction': ['rule', 'quill', 'rubber_eraser', 'fire_screen', 'fountain'], 'response_time_ms': 4083.5109999999995}\n",
      "[4]: result: {'prediction': ['pomegranate', 'strawberry', 'pot', 'hip', 'orange'], 'response_time_ms': 3290.517}\n",
      "[5]: result: {'prediction': ['trimaran', 'catamaran', 'speedboat', 'dock', 'fireboat'], 'response_time_ms': 3381.243}\n",
      "[6]: result: {'prediction': ['miniature_pinscher', 'Chihuahua', 'toy_terrier', 'dingo', 'timber_wolf'], 'response_time_ms': 3901.043}\n",
      "[7]: result: {'prediction': ['trimaran', 'catamaran', 'speedboat', 'dock', 'fireboat'], 'response_time_ms': 3591.697}\n",
      "[8]: result: {'prediction': ['pomegranate', 'strawberry', 'pot', 'hip', 'orange'], 'response_time_ms': 3198.18}\n",
      "[9]: result: {'prediction': ['sarong', 'apron', 'poncho', 'overskirt', 'stole'], 'response_time_ms': 2755.9939999999997}\n",
      "[10]: result: {'prediction': ['valley', 'seashore', 'promontory', 'lakeside', 'cliff'], 'response_time_ms': 2896.875}\n",
      "running tfserving-mobilenetv1 workload function\n",
      "[1]: result: {'prediction': ['mushroom', 'bolete', 'wombat', 'sea_slug', 'hog'], 'response_time_ms': 5551.840999999999}\n",
      "[2]: result: {'prediction': ['lacewing', 'dragonfly', 'scabbard', 'honeycomb', 'terrapin'], 'response_time_ms': 1883.262}\n",
      "[3]: result: {'prediction': ['comic_book', 'kimono', 'toyshop', 'shopping_basket', 'groom'], 'response_time_ms': 1956.593}\n",
      "[4]: result: {'prediction': ['brassiere', 'gasmask', 'seat_belt', 'Band_Aid', 'buckle'], 'response_time_ms': 1670.3619999999999}\n",
      "[5]: result: {'prediction': ['goblet', 'vase', 'pedestal', 'table_lamp', 'bolo_tie'], 'response_time_ms': 843.1840000000001}\n",
      "[6]: result: {'prediction': ['bubble', 'miniskirt', 'buckle', 'necklace', 'planetarium'], 'response_time_ms': 1757.987}\n",
      "[7]: result: {'prediction': ['terrapin', 'mud_turtle', 'platypus', 'dung_beetle', 'American_egret'], 'response_time_ms': 2041.9070000000002}\n",
      "[8]: result: {'prediction': ['red_wine', 'perfume', 'pop_bottle', 'beer_bottle', 'wine_bottle'], 'response_time_ms': 1849.54}\n",
      "[9]: result: {'prediction': ['trimaran', 'catamaran', 'submarine', 'speedboat', 'pole'], 'response_time_ms': 2866.892}\n",
      "[10]: result: {'prediction': ['cowboy_boot', 'doormat', 'shovel', 'barrow', 'swing'], 'response_time_ms': 2374.263}\n"
     ]
    }
   ],
   "source": [
    "# testing the workload functions\n",
    "!python helpers/request_funcs.py"
   ]
  }
 ]
}